{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from collections import Counter;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Customer-Churn-Records.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>9996</td>\n",
       "      <td>15606229</td>\n",
       "      <td>Obijiaku</td>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9997</td>\n",
       "      <td>15569892</td>\n",
       "      <td>Johnstone</td>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9998</td>\n",
       "      <td>15584532</td>\n",
       "      <td>Liu</td>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9999</td>\n",
       "      <td>15682355</td>\n",
       "      <td>Sabbatini</td>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>10000</td>\n",
       "      <td>15628319</td>\n",
       "      <td>Walker</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      RowNumber  CustomerId    Surname  CreditScore Geography  Gender  Age  \\\n",
       "0             1    15634602   Hargrave          619    France  Female   42   \n",
       "1             2    15647311       Hill          608     Spain  Female   41   \n",
       "2             3    15619304       Onio          502    France  Female   42   \n",
       "3             4    15701354       Boni          699    France  Female   39   \n",
       "4             5    15737888   Mitchell          850     Spain  Female   43   \n",
       "...         ...         ...        ...          ...       ...     ...  ...   \n",
       "9995       9996    15606229   Obijiaku          771    France    Male   39   \n",
       "9996       9997    15569892  Johnstone          516    France    Male   35   \n",
       "9997       9998    15584532        Liu          709    France  Female   36   \n",
       "9998       9999    15682355  Sabbatini          772   Germany    Male   42   \n",
       "9999      10000    15628319     Walker          792    France  Female   28   \n",
       "\n",
       "      Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0          2       0.00              1          1               1   \n",
       "1          1   83807.86              1          0               1   \n",
       "2          8  159660.80              3          1               0   \n",
       "3          1       0.00              2          0               0   \n",
       "4          2  125510.82              1          1               1   \n",
       "...      ...        ...            ...        ...             ...   \n",
       "9995       5       0.00              2          1               0   \n",
       "9996      10   57369.61              1          1               1   \n",
       "9997       7       0.00              1          0               1   \n",
       "9998       3   75075.31              2          1               0   \n",
       "9999       4  130142.79              1          1               0   \n",
       "\n",
       "      EstimatedSalary  Exited  Complain  Satisfaction Score Card Type  \\\n",
       "0           101348.88       1         1                   2   DIAMOND   \n",
       "1           112542.58       0         1                   3   DIAMOND   \n",
       "2           113931.57       1         1                   3   DIAMOND   \n",
       "3            93826.63       0         0                   5      GOLD   \n",
       "4            79084.10       0         0                   5      GOLD   \n",
       "...               ...     ...       ...                 ...       ...   \n",
       "9995         96270.64       0         0                   1   DIAMOND   \n",
       "9996        101699.77       0         0                   5  PLATINUM   \n",
       "9997         42085.58       1         1                   3    SILVER   \n",
       "9998         92888.52       1         1                   2      GOLD   \n",
       "9999         38190.78       0         0                   3   DIAMOND   \n",
       "\n",
       "      Point Earned  \n",
       "0              464  \n",
       "1              456  \n",
       "2              377  \n",
       "3              350  \n",
       "4              425  \n",
       "...            ...  \n",
       "9995           300  \n",
       "9996           771  \n",
       "9997           564  \n",
       "9998           339  \n",
       "9999           911  \n",
       "\n",
       "[10000 rows x 18 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Unwanted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['CustomerId','RowNumber','Surname','Complain'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>771</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>96270.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>516</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>57369.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101699.77</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>PLATINUM</td>\n",
       "      <td>771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>709</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>42085.58</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>772</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Male</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>75075.31</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>92888.52</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>130142.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38190.78</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>DIAMOND</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore Geography  Gender  Age  Tenure    Balance  NumOfProducts  \\\n",
       "0             619    France  Female   42       2       0.00              1   \n",
       "1             608     Spain  Female   41       1   83807.86              1   \n",
       "2             502    France  Female   42       8  159660.80              3   \n",
       "3             699    France  Female   39       1       0.00              2   \n",
       "4             850     Spain  Female   43       2  125510.82              1   \n",
       "...           ...       ...     ...  ...     ...        ...            ...   \n",
       "9995          771    France    Male   39       5       0.00              2   \n",
       "9996          516    France    Male   35      10   57369.61              1   \n",
       "9997          709    France  Female   36       7       0.00              1   \n",
       "9998          772   Germany    Male   42       3   75075.31              2   \n",
       "9999          792    France  Female   28       4  130142.79              1   \n",
       "\n",
       "      HasCrCard  IsActiveMember  EstimatedSalary  Exited  Satisfaction Score  \\\n",
       "0             1               1        101348.88       1                   2   \n",
       "1             0               1        112542.58       0                   3   \n",
       "2             1               0        113931.57       1                   3   \n",
       "3             0               0         93826.63       0                   5   \n",
       "4             1               1         79084.10       0                   5   \n",
       "...         ...             ...              ...     ...                 ...   \n",
       "9995          1               0         96270.64       0                   1   \n",
       "9996          1               1        101699.77       0                   5   \n",
       "9997          0               1         42085.58       1                   3   \n",
       "9998          1               0         92888.52       1                   2   \n",
       "9999          1               0         38190.78       0                   3   \n",
       "\n",
       "     Card Type  Point Earned  \n",
       "0      DIAMOND           464  \n",
       "1      DIAMOND           456  \n",
       "2      DIAMOND           377  \n",
       "3         GOLD           350  \n",
       "4         GOLD           425  \n",
       "...        ...           ...  \n",
       "9995   DIAMOND           300  \n",
       "9996  PLATINUM           771  \n",
       "9997    SILVER           564  \n",
       "9998      GOLD           339  \n",
       "9999   DIAMOND           911  \n",
       "\n",
       "[10000 rows x 14 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore           0\n",
      "Geography             0\n",
      "Gender                0\n",
      "Age                   0\n",
      "Tenure                0\n",
      "Balance               0\n",
      "NumOfProducts         0\n",
      "HasCrCard             0\n",
      "IsActiveMember        0\n",
      "EstimatedSalary       0\n",
      "Exited                0\n",
      "Satisfaction Score    0\n",
      "Card Type             0\n",
      "Point Earned          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill missing values with the mode of each column  \n",
    "for column in df.columns:  \n",
    "    mode_value = df[column].mode().iloc[0]  # Get the first mode value  \n",
    "    df[column].fillna(mode_value, inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CreditScore           0\n",
      "Geography             0\n",
      "Gender                0\n",
      "Age                   0\n",
      "Tenure                0\n",
      "Balance               0\n",
      "NumOfProducts         0\n",
      "HasCrCard             0\n",
      "IsActiveMember        0\n",
      "EstimatedSalary       0\n",
      "Exited                0\n",
      "Satisfaction Score    0\n",
      "Card Type             0\n",
      "Point Earned          0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling Categorical Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.preprocessing import LabelEncoder  \n",
    "\n",
    "\n",
    "# Identify categorical columns  \n",
    "categorical_columns = df.select_dtypes(include=['object', 'category']).columns  \n",
    "\n",
    "# Initialize LabelEncoder  \n",
    "label_encoder = LabelEncoder()  \n",
    "\n",
    "# Apply LabelEncoder to categorical columns  \n",
    "for column in categorical_columns:  \n",
    "    df[column] = label_encoder.fit_transform(df[column])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       0\n",
      "2       1\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "9995    0\n",
      "9996    0\n",
      "9997    1\n",
      "9998    1\n",
      "9999    0\n",
      "Name: Exited, Length: 10000, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Counter({0: 7962, 1: 2038})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df['Exited'])\n",
    "Counter(df['Exited'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "y = df['Exited']\n",
    "X = df.drop('Exited',axis=1) \n",
    "# Here we assume any numeric column needs scaling  \n",
    "numerical_columns = X.select_dtypes(include=['int64', 'float64','int32']).columns  \n",
    "\n",
    "# Step 3: Apply Z-score Normalization  \n",
    "scaler = StandardScaler()  \n",
    "X[numerical_columns] = scaler.fit_transform(X[numerical_columns])  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Satisfaction Score</th>\n",
       "      <th>Card Type</th>\n",
       "      <th>Point Earned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.326221</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>-0.721130</td>\n",
       "      <td>-1.339533</td>\n",
       "      <td>-0.630839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.440036</td>\n",
       "      <td>1.515067</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.198164</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>0.117350</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.216534</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>-1.339533</td>\n",
       "      <td>-0.666251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.536794</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>1.032908</td>\n",
       "      <td>1.333053</td>\n",
       "      <td>2.527057</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>0.240687</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>-1.339533</td>\n",
       "      <td>-1.015942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.501521</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-1.387538</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.108918</td>\n",
       "      <td>1.412812</td>\n",
       "      <td>-0.445319</td>\n",
       "      <td>-1.135457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.063884</td>\n",
       "      <td>1.515067</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>0.388871</td>\n",
       "      <td>-1.041760</td>\n",
       "      <td>0.785728</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-0.365276</td>\n",
       "      <td>1.412812</td>\n",
       "      <td>-0.445319</td>\n",
       "      <td>-0.803472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>1.246488</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.007457</td>\n",
       "      <td>-0.004426</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.066419</td>\n",
       "      <td>-1.432445</td>\n",
       "      <td>-1.339533</td>\n",
       "      <td>-1.356781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>-1.391939</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>-0.373958</td>\n",
       "      <td>1.724464</td>\n",
       "      <td>-0.306379</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>0.027988</td>\n",
       "      <td>1.412812</td>\n",
       "      <td>0.448895</td>\n",
       "      <td>0.728088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>0.604988</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-0.278604</td>\n",
       "      <td>0.687130</td>\n",
       "      <td>-1.225848</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>-1.547768</td>\n",
       "      <td>0.970243</td>\n",
       "      <td>-1.008643</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>1.343109</td>\n",
       "      <td>-0.188192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1.256835</td>\n",
       "      <td>0.306591</td>\n",
       "      <td>0.912419</td>\n",
       "      <td>0.293517</td>\n",
       "      <td>-0.695982</td>\n",
       "      <td>-0.022608</td>\n",
       "      <td>0.807737</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-0.125231</td>\n",
       "      <td>-0.721130</td>\n",
       "      <td>-0.445319</td>\n",
       "      <td>-1.184148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>1.463771</td>\n",
       "      <td>-0.901886</td>\n",
       "      <td>-1.095988</td>\n",
       "      <td>-1.041433</td>\n",
       "      <td>-0.350204</td>\n",
       "      <td>0.859965</td>\n",
       "      <td>-0.911583</td>\n",
       "      <td>0.646092</td>\n",
       "      <td>-1.030670</td>\n",
       "      <td>-1.076370</td>\n",
       "      <td>-0.009816</td>\n",
       "      <td>-1.339533</td>\n",
       "      <td>1.347794</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreditScore  Geography    Gender       Age    Tenure   Balance  \\\n",
       "0       -0.326221  -0.901886 -1.095988  0.293517 -1.041760 -1.225848   \n",
       "1       -0.440036   1.515067 -1.095988  0.198164 -1.387538  0.117350   \n",
       "2       -1.536794  -0.901886 -1.095988  0.293517  1.032908  1.333053   \n",
       "3        0.501521  -0.901886 -1.095988  0.007457 -1.387538 -1.225848   \n",
       "4        2.063884   1.515067 -1.095988  0.388871 -1.041760  0.785728   \n",
       "...           ...        ...       ...       ...       ...       ...   \n",
       "9995     1.246488  -0.901886  0.912419  0.007457 -0.004426 -1.225848   \n",
       "9996    -1.391939  -0.901886  0.912419 -0.373958  1.724464 -0.306379   \n",
       "9997     0.604988  -0.901886 -1.095988 -0.278604  0.687130 -1.225848   \n",
       "9998     1.256835   0.306591  0.912419  0.293517 -0.695982 -0.022608   \n",
       "9999     1.463771  -0.901886 -1.095988 -1.041433 -0.350204  0.859965   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  \\\n",
       "0         -0.911583   0.646092        0.970243         0.021886   \n",
       "1         -0.911583  -1.547768        0.970243         0.216534   \n",
       "2          2.527057   0.646092       -1.030670         0.240687   \n",
       "3          0.807737  -1.547768       -1.030670        -0.108918   \n",
       "4         -0.911583   0.646092        0.970243        -0.365276   \n",
       "...             ...        ...             ...              ...   \n",
       "9995       0.807737   0.646092       -1.030670        -0.066419   \n",
       "9996      -0.911583   0.646092        0.970243         0.027988   \n",
       "9997      -0.911583  -1.547768        0.970243        -1.008643   \n",
       "9998       0.807737   0.646092       -1.030670        -0.125231   \n",
       "9999      -0.911583   0.646092       -1.030670        -1.076370   \n",
       "\n",
       "      Satisfaction Score  Card Type  Point Earned  \n",
       "0              -0.721130  -1.339533     -0.630839  \n",
       "1              -0.009816  -1.339533     -0.666251  \n",
       "2              -0.009816  -1.339533     -1.015942  \n",
       "3               1.412812  -0.445319     -1.135457  \n",
       "4               1.412812  -0.445319     -0.803472  \n",
       "...                  ...        ...           ...  \n",
       "9995           -1.432445  -1.339533     -1.356781  \n",
       "9996            1.412812   0.448895      0.728088  \n",
       "9997           -0.009816   1.343109     -0.188192  \n",
       "9998           -0.721130  -0.445319     -1.184148  \n",
       "9999           -0.009816  -1.339533      1.347794  \n",
       "\n",
       "[10000 rows x 13 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 7286, 0: 4976})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN  \n",
    "smote_enn = SMOTEENN(random_state=42)  \n",
    "X, y = smote_enn.fit_resample(X, y)\n",
    "Counter(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9200978393803506\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.92      0.90      1013\n",
      "           1       0.94      0.92      0.93      1440\n",
      "\n",
      "    accuracy                           0.92      2453\n",
      "   macro avg       0.92      0.92      0.92      2453\n",
      "weighted avg       0.92      0.92      0.92      2453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  \n",
    "from sklearn.svm import SVC  \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)  \n",
    " \n",
    "\n",
    "# Step 5: Create and train the SVM model  \n",
    "model = SVC(kernel='rbf', class_weight='balanced', random_state=42)  # You can change the kernel to 'rbf', 'poly', etc.  \n",
    "model.fit(X_train, y_train)  \n",
    "\n",
    "# Step 6: Make predictions  \n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "# Step 7: Evaluate the model  \n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "report = classification_report(y_test, y_pred)  \n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy)  \n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.9442783365044849\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93      1493\n",
      "           1       0.94      0.96      0.95      2186\n",
      "\n",
      "    accuracy                           0.94      3679\n",
      "   macro avg       0.94      0.94      0.94      3679\n",
      "weighted avg       0.94      0.94      0.94      3679\n",
      "\n",
      "\n",
      "Feature Importances:\n",
      "               Feature  Importance\n",
      "3                  Age    0.261296\n",
      "6        NumOfProducts    0.212260\n",
      "5              Balance    0.105671\n",
      "1            Geography    0.061448\n",
      "12        Point Earned    0.052594\n",
      "8       IsActiveMember    0.049413\n",
      "9      EstimatedSalary    0.049265\n",
      "0          CreditScore    0.047886\n",
      "4               Tenure    0.045795\n",
      "10  Satisfaction Score    0.040649\n",
      "11           Card Type    0.034464\n",
      "2               Gender    0.028832\n",
      "7            HasCrCard    0.010428\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  \n",
    "from sklearn.ensemble import RandomForestClassifier  \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "# Step 3: Split the dataset into training and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)  \n",
    "\n",
    "# Step 4: Scale features if needed  \n",
    "scaler = StandardScaler()  \n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "# Step 5: Create and train the Random Forest model  \n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)  # You can adjust n_estimators  \n",
    "model.fit(X_train, y_train)  \n",
    "\n",
    "# Step 6: Make predictions  \n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "# Step 7: Evaluate the model  \n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "report = classification_report(y_test, y_pred)  \n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy)  \n",
    "print(\"\\nClassification Report:\\n\", report)  \n",
    "\n",
    "# Step 8: Feature importance  \n",
    "importances = model.feature_importances_  \n",
    "feature_names = X.columns  \n",
    "\n",
    "# Combine feature names and their importances into a DataFrame  \n",
    "feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': importances})  \n",
    "\n",
    "# Sort the DataFrame by importance  \n",
    "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)  \n",
    "\n",
    "# Display the feature importances  \n",
    "print(\"\\nFeature Importances:\")  \n",
    "print(feature_importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8320423970648186\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.74      0.78      1013\n",
      "           1       0.83      0.90      0.86      1440\n",
      "\n",
      "    accuracy                           0.83      2453\n",
      "   macro avg       0.83      0.82      0.82      2453\n",
      "weighted avg       0.83      0.83      0.83      2453\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  \n",
    "from sklearn.naive_bayes import GaussianNB  \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "from imblearn.combine import SMOTEENN  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)  \n",
    "  \n",
    "# Step 4: Create and train the Naive Bayes model  \n",
    "model = GaussianNB()  \n",
    "model.fit(X_train, y_train)  \n",
    "\n",
    "# Step 5: Make predictions  \n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "# Step 6: Evaluate the model  \n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "report = classification_report(y_test, y_pred)  \n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy)  \n",
    "print(\"\\nClassification Report:\\n\", report)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NaiveBayes From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.8320423970648186\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.83      0.84      1408\n",
      "           1       0.84      0.85      0.84      1433\n",
      "\n",
      "    accuracy                           0.84      2841\n",
      "   macro avg       0.84      0.84      0.84      2841\n",
      "weighted avg       0.84      0.84      0.84      2841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class GaussianNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.mean = {}\n",
    "        self.var = {}\n",
    "        self.priors = {}\n",
    "\n",
    "        for c in self.classes:\n",
    "            X_c = X[y == c]\n",
    "            self.mean[c] = np.mean(X_c, axis=0)\n",
    "            self.var[c] = np.var(X_c, axis=0)\n",
    "            self.priors[c] = len(X_c) / len(X)\n",
    "\n",
    "    def gaussian_pdf(self, x, mean, var):\n",
    "        eps = 1e-9  # Avoid division by zero\n",
    "        coef = 1.0 / np.sqrt(2 * np.pi * var + eps)\n",
    "        exponent = np.exp(-(x - mean)**2 / (2 * var + eps))\n",
    "        return coef * exponent\n",
    "\n",
    "    def predict(self, X):\n",
    "        predictions = []\n",
    "        for x in X:\n",
    "            posteriors = []\n",
    "            for c in self.classes:\n",
    "                prior = np.log(self.priors[c])\n",
    "                conditional = np.sum(np.log(self.gaussian_pdf(x, self.mean[c], self.var[c])))\n",
    "                posterior = prior + conditional\n",
    "                posteriors.append(posterior)\n",
    "            predictions.append(self.classes[np.argmax(posteriors)])\n",
    "        return np.array(predictions)\n",
    "\n",
    "from imblearn.combine import SMOTEENN  \n",
    "smote_enn = SMOTEENN(random_state=42)  \n",
    "XX, yy = smote_enn.fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX,yy, test_size=0.2, random_state=42)  \n",
    "#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=42)\n",
    "X_train = X_train.to_numpy()  \n",
    "X_test = X_test.to_numpy()  \n",
    "\n",
    "# Initialize and train the custom model\n",
    "gnb = GaussianNaiveBayes()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nAccuracy:\", accuracy)  \n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7866948257655755\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.79      0.78      1392\n",
      "           1       0.80      0.78      0.79      1449\n",
      "\n",
      "    accuracy                           0.79      2841\n",
      "   macro avg       0.79      0.79      0.79      2841\n",
      "weighted avg       0.79      0.79      0.79      2841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler  \n",
    "from sklearn.linear_model import LogisticRegression  \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "\n",
    "\n",
    "# Step 3: Split the dataset into training and test sets  \n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.2, random_state=42, stratify=yy)  \n",
    "\n",
    "# Step 4: Scale features  \n",
    "scaler = StandardScaler()  \n",
    "X_train = scaler.fit_transform(X_train)  \n",
    "X_test = scaler.transform(X_test)  \n",
    "\n",
    "# Step 5: Create and train the Logistic Regression model  \n",
    "model = LogisticRegression(random_state=42)  \n",
    "model.fit(X_train, y_train)  \n",
    "\n",
    "# Step 6: Make predictions  \n",
    "y_pred = model.predict(X_test)  \n",
    "\n",
    "# Step 7: Evaluate the model  \n",
    "accuracy = accuracy_score(y_test, y_pred)  \n",
    "report = classification_report(y_test, y_pred)  \n",
    "\n",
    "print(\"\\nAccuracy:\", accuracy)  \n",
    "print(\"\\nClassification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7866948257655755\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.79      0.78      1408\n",
      "           1       0.79      0.76      0.78      1433\n",
      "\n",
      "    accuracy                           0.78      2841\n",
      "   macro avg       0.78      0.78      0.78      2841\n",
      "weighted avg       0.78      0.78      0.78      2841\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(XX, yy, test_size=0.2, random_state=42)\n",
    "\n",
    "# Add bias term to the features (intercept)\n",
    "X_train_biased = np.c_[np.ones(X_train.shape[0]), X_train]\n",
    "X_test_biased = np.c_[np.ones(X_test.shape[0]), X_test]\n",
    "\n",
    "# Initialize parameters\n",
    "weights = np.zeros(X_train_biased.shape[1])\n",
    "learning_rate = 0.01\n",
    "num_epochs = 1000\n",
    "\n",
    "# Train the model using gradient descent\n",
    "for epoch in range(num_epochs):\n",
    "    # Compute predictions\n",
    "    predictions = X_train_biased.dot(weights)\n",
    "    \n",
    "    # Compute the gradient\n",
    "    errors = predictions - y_train\n",
    "    gradient = X_train_biased.T.dot(errors) / len(y_train)\n",
    "    \n",
    "    # Update weights\n",
    "    weights -= learning_rate * gradient\n",
    "\n",
    "# Make predictions on the test set\n",
    "test_predictions = X_test_biased.dot(weights)\n",
    "\n",
    "# Convert predictions to binary (0 or 1) using a threshold of 0.5\n",
    "y_pred = (test_predictions >= 0.5).astype(int)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"\\nAccuracy:\", accuracy)  \n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
